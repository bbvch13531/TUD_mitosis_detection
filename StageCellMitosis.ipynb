{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage of Cell Mitosis Detection - Group Assessment - IDSP1704\n",
    "#### Scott Donnelly, Louis Chavez, Kyungyoung Her"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mitosis is when a mother cell splits into two genetically similar daughter cells. There are several stages to this:\n",
    "- Interphase\n",
    "- Prophase\n",
    "- Metaphase\n",
    "- Anaphase\n",
    "- Telophase\n",
    "- Cytokensis\n",
    "\n",
    "The main objective of this project is to be able to identify when cell is in:\n",
    "- Interphase\n",
    "- Metaphase\n",
    "- Anaphase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods:\n",
    "\n",
    "### compareROI: Compare the nucleus in the video to our reference image to determine mitosis stage\n",
    "#### Parameters:\n",
    "- Binary mask of frame from video\n",
    "- x coordinate of bounding rectangle of nucleus\n",
    "- y coordinate of bounding rectangle of nucleus\n",
    "- width of bounding rectangle of nucleus\n",
    "- height of bounding rectangle of nucleus\n",
    "\n",
    "#### Algorithm:\n",
    "- Crop ROI from mask of video\n",
    "- For each reference image compare the cropped ROI to the shape of the reference image using cv2.matchShapes\n",
    "- If it's the first image then set that as the closest match and save the index\n",
    "- If matchShapes returns smaller value then change the value\n",
    "- Return the index of the closest match\n",
    "\n",
    "This function is called for each frame of the video\n",
    "\n",
    "### createRefMasks: Create masks from reference images of the phases to be identifed. Interphase,  Metaphase, Anaphase\n",
    "#### Parameters:\n",
    "- None\n",
    "\n",
    "#### Algorithm:\n",
    "- Loop through each reference image\n",
    "- Threshold to get mask\n",
    "- Morphological closing and opening to fill and holes\n",
    "- Resize the reference\n",
    "- Append to list\n",
    "- Return list of reference images\n",
    "        \n",
    "These masks are then used for shape comparison to objects tracked in the input video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Process reference images\n",
    "2. Load the video\n",
    "3. Identify cells/nucleus using thresholding and contours\n",
    "4. Box the cells\n",
    "5. Compare boxed cells to reference image using matchShapes in compareROI\n",
    "6. Name the stage of mitosis of cell based on the index returned from compareROI\n",
    "7. Repeat for each frame until finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import image as image\n",
    "\n",
    "vid = cv2.VideoCapture('mitosiscell360.mp4')\n",
    "(check, frame) = vid.read()\n",
    "frame_counter = 0\n",
    "stage_string = ['Interphase', 'Metaphase', 'Anaphase']\n",
    "\n",
    "def createRefMasks():\n",
    "    \"\"\"\n",
    "    This function is used to create masks from reference images of the phases to be identifed.\n",
    "    - Interphase\n",
    "    - Metaphase\n",
    "    - Anaphase\n",
    "        \n",
    "    These masks are then used for shape comparison to objects tracked in the input video\n",
    "    \"\"\"\n",
    "    ref_strings = ['interphase_ref2_focus.jpg', 'metaphase_ref_focus.jpg', 'anaphase_ref_focus.jpg']\n",
    "    ref_images = []\n",
    "\n",
    "    for i in range(0,len(ref_strings)):\n",
    "        ref_image = cv2.imread(ref_strings[i])\n",
    "        G = cv2.cvtColor(ref_image, cv2.COLOR_BGR2GRAY)\n",
    "        ret,thresh = cv2.threshold(G, 140, 235, cv2.THRESH_BINARY_INV)\n",
    "        shape = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5,5))\n",
    "        CloseRef = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, shape, iterations=2)\n",
    "        OpenRef = cv2.morphologyEx(CloseRef, cv2.MORPH_OPEN, shape, iterations=2)\n",
    "        OpenRef = cv2.resize(OpenRef, (100,100))\n",
    "        ref_images.append(OpenRef)\n",
    "        #cv2.imshow(\"ref\", ref_images[i])\n",
    "        cv2.waitKey(0)\n",
    "        \n",
    "    return ref_images\n",
    "        \n",
    "        \n",
    "def compareROI(ref_images,mask, x, y, w, h):\n",
    "    \"\"\"\n",
    "    This function uses the OpenCV matchShapes() function to compare the shapes found in the\n",
    "    video frames with the masks made from reference images. The index returned is to identify the\n",
    "    labels used on the video.\n",
    "    \"\"\"\n",
    "    match = 0\n",
    "    for i in range(0,len(ref_images)):\n",
    "        ROI = cv2.resize(mask[y:y+h, x:x+w], (100,100))\n",
    "        diff = cv2.matchShapes(ROI, ref_images[i], 1, 0.0)\n",
    "        if i == 0 or match > diff:\n",
    "            match = diff\n",
    "            index = i\n",
    "            \n",
    "    return index\n",
    "\n",
    "ref_images = createRefMasks()\n",
    "\n",
    "while True:\n",
    "    \n",
    "    # Continuous Video Loop\n",
    "    frame_counter += 1\n",
    "    if frame_counter == vid.get(cv2.CAP_PROP_FRAME_COUNT):\n",
    "        frame_counter = 0\n",
    "        vid.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "    \n",
    "    # Thresholding and object detection on the video frames\n",
    "    ret,thresh = cv2.threshold(frame[:,:,2], 100, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU) # Otsu is auto-global thresholding\n",
    "    shape = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5,5))\n",
    "    dilated = cv2.dilate(thresh, shape, iterations=2)\n",
    "    Close = cv2.morphologyEx(dilated, cv2.MORPH_CLOSE, shape)\n",
    "    contours, _ = cv2.findContours(Close, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Loop to detect shapes and draw the rectangles and label the phases for each frame.\n",
    "    for c in contours:\n",
    "        if cv2.contourArea(c) > 1000:\n",
    "            # Epsilon is the maximum distance from contour to approx contour\n",
    "            # Epsilon = error_rate * actual_arc_length\n",
    "            epsilon = 0.01 * cv2.arcLength(c, True)\n",
    "            approx = cv2.approxPolyDP(c, epsilon, True)\n",
    "            \n",
    "            # PolyDP provides accurate contouring and object detection.\n",
    "            #frame = cv2.drawContours(frame, [approx], 0, (0,255,0), 1)\n",
    "\n",
    "            rect = max(contours,key = cv2.contourArea)\n",
    "            x,y,w,h = cv2.boundingRect(c)\n",
    "            stage = compareROI(ref_images, Close, x, y, w, h)\n",
    "            cv2.putText(frame, stage_string[stage], (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (250,120,0), 2)\n",
    "            frame = cv2.rectangle(frame,(x,y),(x+w,y+h),(250,120,0),2)\n",
    "    \n",
    "    #cv2.imshow(\"Masking\", Close)\n",
    "    cv2.imshow(\"Video - press \\\"q\\\" to stop an any key to close\", frame)\n",
    "    # Slows the frame rate.\n",
    "    cv2.waitKey(50)\n",
    "    \n",
    "    # This delays while waiting for a key to be pressed\n",
    "    key = cv2.waitKey(50)\n",
    "\n",
    "    # If the 'q' key is pressed, quit:\n",
    "    if key == ord(\"q\"):\n",
    "         break\n",
    "            \n",
    "    # Next Frame:\n",
    "    (check, frame) = vid.read()\n",
    "\n",
    "    \n",
    "#Release video and close windows after the loop ends.    \n",
    "vid.release()\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Analysis:\n",
    "\n",
    "The results of our program show that we are able to identify two out of three of our main goal. We are able to successfully identify when the cells are in interphase and metaphase for most of the time. Our design however is flawed in that it relies on the quality of the reference image and cannot take into account when the the chromosomes split during anaphase as when this occurs our program identifies two new blobs which are generally identical to interphase. To possibly fix this we need to find a way to detect nucleus more accurately or find a way to track the actual cell so that we can identify if there more than one nuclei in the cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
